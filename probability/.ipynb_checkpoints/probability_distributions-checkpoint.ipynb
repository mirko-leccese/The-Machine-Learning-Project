{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "229e0416-b855-45d2-a0c5-ed7cdaf5eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0baf8-af09-4eac-9ac9-f91f42a5d4f7",
   "metadata": {},
   "source": [
    "# An informal Introduction to Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04031728-b264-4077-8e3f-c283d2265564",
   "metadata": {},
   "source": [
    "In this notebook, we provide a relatively informal introduction the concept of **probability distribution*. The significance of this subject lies in its foundational role across various disciplines (data science as well as scientic subjects such as physics or chemistry), where understanding the probability distribution shapes of data or phenomena under examination serves as a starting point for most applications. There are lots of mathematical details that could be covered when talking about probability distributions, since the subject is vast and can be discussed under different persepctives. The aim of this notebook is to provide just an introductory overview, but without compromising too heavily on the mathematical aspects. Specifically, we will delve into some of the most prevalent probability distributions and their properties, such as the *Gaussian* or *Beta* distribution. Additionally, we will include Python simulations to facilitate a better grasp of the concepts discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3eaca-238c-4237-b951-0bb3241c38ec",
   "metadata": {},
   "source": [
    "## Probability Densities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf681e03-8655-4f78-ae5b-a83e7af0e788",
   "metadata": {},
   "source": [
    "In a *frequentistic* approach, we define the probability of an event as a measure of the frequency for the event to occur, in the limit that the total number of trials goes to infinity. For instance, the probabilty of rolling a dice and get \"head\" is 1/2, since in the limit of an infinite number of trials, we should expect to get \"head\" half of the time and \"tail\" the other half. Such probabilities are defined over discrete sets of events, in the provided example $\\{H, T\\}$, i.e. \"head\" or \"tail\". However, most of the time we deal with continuous variables and we need to extend probabilities to such a continiuous case. \n",
    "\n",
    "If $x$ is a real-value continious variable, the *probability density* over $x$ is the defined as the quantity $p(x)$ such that $p(x)\\delta x$ is the probability for $x$ to fall in the interval $(x, x+\\delta x)$, in the limit $\\delta x \\to 0$. Then, we may define:\n",
    "\n",
    "$$P(x \\in (a, b)) = \\int_a^b p(x) dx $$\n",
    "\n",
    "which is the probability for $x$ to fall in the interval $(a, b)$. The probability density $p(x)$ must satisfy the following two conditions:\n",
    "$$ \\begin{gather}\n",
    "p(x) \\geq 0 \\\\\n",
    "\\int_{-\\infty}^{+\\infty} p(x) dx = 1\n",
    "\\end{gather}\n",
    "$$\n",
    "The sum and product rules, as well as Beyes' Theorem, apply equally to the case of probability densities. If $x$ and$y$ are two real variables, then the product and sum rules take the form:\n",
    "$$\\begin{gather}\n",
    "p(x) = \\int p(x,y) dy \\\\\n",
    "p(x,y) = p(y|x) p(x)\n",
    "\\end{gather}\n",
    "$$\n",
    "where $p(y|x)$ is the *conditional probability* of y given x. \n",
    "In analogy with the discrete case, we may define the average value of some function $f(x)$, assuming that  $x$ follows the probability distributions $p(x)$, as:\n",
    "$$\n",
    "\\mathbb{E}[f] = \\int p(x) f(x) dx\n",
    "$$\n",
    "The operator $\\mathbb{E}(\\cdot)$ is generally known as the **expectation** (of $f(x)$). The **variance** of $f(x)$ is instead a quantity measuring the variability in $f(x)$ around its mean value $\\mathbb{E}[f(x)]$ and is defined as:\n",
    "$$\n",
    "\\text{var}[f] = \\mathbb{E}[(f(x)-\\mathbb{E}[f(x)])^2]\n",
    "$$\n",
    "in other words, it is the expectation value of the squared difference between $f(x)$ and its mean value. We take the *squared* difference since the expected value of the mere difference $f(x) - \\mathbb{E}[f(x)]$ is identically vanishing. Working out the expected value and reminding that $\\mathbb{E}$ is a *linear* operator, we can re-write the variance in a pretty simple form: \n",
    "$$\\begin{align}\n",
    "\\text{var}[f(x)] &= \\mathbb{E}[f(x)^2 -2f(x)E[f(x)] + (\\mathbb{E}[f(x)])^2] \\\\\n",
    "&=\\mathbb{E}[f(x)^2] - 2(\\mathbb{E}[f(x)])^2+(\\mathbb{E}[f(x)])^2 \\\\\n",
    "&= \\mathbb{E}[f(x)^2]-\\mathbb{E}[f(x)]^2\n",
    "\\end{align}\n",
    "$$\n",
    "For two random variables $x$ and $y$ we define also the **covariance** as:\n",
    "$$\\begin{align}\n",
    "\\text{cov}[x,y] &= \\mathbb{E}_{x,y}[\\{x-\\mathbb{E}[x]\\}\\{y-\\mathbb{E}[y]\\}] \\\\\n",
    "&=\\mathbb{E}_{x,y}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]\n",
    "\\end{align}\n",
    "$$\n",
    "which expresses the extent to which $x$ and $y$ vary together (i.e. \"co-vary\"). Indeed, if $x$ and $y$ are independent variables, then:\n",
    "$$\\begin{align}\n",
    "\\mathbb{E}_{x,y}[xy] &= \\int \\int xy p(x)p(y) dxdy \\\\\n",
    "&= \\left( \\int x p(x) dx)\\right) \\left( \\int y p(y) dy\\right) \\\\\n",
    "&= \\mathbb{E}_x[x]\\mathbb{E}_y[y]\n",
    "\\end{align}\n",
    "$$\n",
    "hence their covariance vanishes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e88ccee-2e19-4a75-9cb5-a460f9db35dd",
   "metadata": {},
   "source": [
    "## The Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacbc11-83a7-42d6-9a75-77e21e320f88",
   "metadata": {},
   "source": [
    "We start by discussing one of the most important probability distribution in maths and science in general, the so-called **normal** or **Gaussian distribution**. Let first consider the simplest case of a single real-valued variable $x$, for which the Gaussian distribution is defined as:\n",
    "$$\n",
    "\\mathcal{N}(x|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left({-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\\right)\n",
    "$$\n",
    "The distribution is governed by two parameters: $\\mu$, called the *mean*, and $\\sigma^2$, called the *variance*. These names will be justified in the following. The square root of variance, i.e. $\\sigma$, is called the *standard deviation*, while the reciprocal value of the variance is generally known as the *precision*, $\\beta = 1/\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6035727-5e1e-4998-bd1e-579e527ff62e",
   "metadata": {},
   "source": [
    "In the cells below, we write a simple function to plot a Gaussian distribution to see how its shape change according to different values of mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ef3b65d-788a-4c4f-8ca8-e11c4608870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "x_grid = np.linspace(-100, 100, num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8651bf13-39f5-462e-9d0a-289b502f6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian(x: np.array, mu: float, sigma: float) -> np.array:\n",
    "    '''\n",
    "    Function returning Gaussian distribution y values given:\n",
    "\n",
    "    :params x: numpy array defining x values\n",
    "    :params mu: float defining the mean\n",
    "    :params sigma: float defining the variance\n",
    "    '''\n",
    "    a = 1/np.sqrt(2*np.pi*sigma**2)\n",
    "    b = -1/(2*sigma**2)\n",
    "\n",
    "    return a * np.exp(b*(x-mu)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd119dec-0fb7-4074-b416-eaac91683b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian(mu: float , sigma: float):\n",
    "    '''\n",
    "    Function returning the plot of a Gaussian distribution given:\n",
    "\n",
    "    :params mu: its mean\n",
    "    :params sigma: its variance \n",
    "    '''\n",
    "\n",
    "    y = generate_gaussian(x_grid, mu, sigma)\n",
    "\n",
    "    # Plot histograms of sample means\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    fig.suptitle('The Gaussian Distribution')\n",
    "\n",
    "    ax.plot(x, y, color='royalblue', linewidth=2)\n",
    "    # Fill the area under the plot with light blue color\n",
    "    ax.fill_between(x, y, color='lightblue', alpha=0.2)\n",
    "\n",
    "    # Plotting vertical lines at \\mu+\\sigma and \\mu-\\sigma\n",
    "    ax.axvline(mu+sigma, linestyle=\"--\", color=\"red\", linewidth=2)\n",
    "    ax.axvline(mu-sigma, linestyle=\"--\", color=\"red\", linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel(r'$\\mathcal{N}(x|\\mu, \\sigma^2)$')\n",
    "    ax.set_title(fr\"Parameters: $\\mu$ = {mu}, $\\sigma$={round(sigma, 1)}\")\n",
    "\n",
    "    # Add grid lines\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51d10f6b-afb2-4ae4-8936-ca02f68320b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2a349488344decb34a3e812a97a2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mu', max=20.0, min=-20.0, step=0.5), FloatSlider(valâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_gaussian(mu: float, sigma: float)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate Central Limit Theorem\n",
    "ipywidgets.interact(plot_gaussian, mu=(-20,20,0.5), sigma=(0.1, 50, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545b130-591a-4e57-90b4-ef27e6c71fd7",
   "metadata": {},
   "source": [
    "It is straightforward to show that the Gaussian distribution is normalized, as expected from a proper probability distribution:\n",
    "$$\n",
    "\\int_{-\\infty}^{+\\infty} \\mathcal{N} (x|\\mu, \\sigma^2) dx = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\cdot \\sqrt{\\frac{\\pi}{\\beta/2}} \\equiv 1\n",
    "$$\n",
    "since $\\int_{-\\infty}^{+\\infty} \\exp{(-\\alpha x^2)} = \\sqrt{\\pi/a}$. Let verify that the `generate_gaussian` function defined above actually defines a proper Gaussian distribution, computing numerically its integral by means of the `scipy.quad` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f38f6e4-d89a-4272-9b38-3fe005cd45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "mu = 0\n",
    "sigma = 1\n",
    "\n",
    "# Integrate the Gaussian function from -infinity to +infinity\n",
    "integral, _ = quad(generate_gaussian, -np.inf, np.inf, args=(mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7143c69b-b73d-4c3b-b7a1-9a74b377f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The integral of the Gaussian distribution is: 0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "print(f\"The integral of the Gaussian distribution is: {integral}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d5c08-3c8f-41ca-955f-d8491b5fcacf",
   "metadata": {},
   "source": [
    "Let now give a brief justification of the term *mean* and *variance*. We consider a real-value variable $x$ distributed according to a Gaussian distribution of mean $\\mu$ and standard deviation $\\sigma$. We can then compute the expectation value of $x$ under such Gaussian distribution as:\n",
    "$$\n",
    "\\mathbb{E}[x] = \\int_{-\\infty}^{+\\infty} \\mathcal{N}(x | \\mu, \\sigma^2) x dx\n",
    "$$\n",
    "We could perform the integration analytically but we skip such simple but boring calculations here. Instead, let compute the integral using again the `quad` method from `scipy`. We perform the numerical integration for different pairs of $(\\mu, \\sigma)$ and look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9743519b-b2cb-47fe-a55c-8d9fc73db230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_expectation_integrand(x, mu, sigma):\n",
    "    return x*generate_gaussian(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "adc49ba7-5a57-4705-9940-c163800509e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "mu_values = [0, 1, 1.5, 2, 2.5, 5, 10.5]\n",
    "sigma_values = [1, 1.5, 2, 2.5, 5, 10.5, 11]\n",
    "\n",
    "params = list(zip(mu_values, sigma_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3d8b55e7-f836-4c37-aec1-26cf5c3a12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation_dict = {}\n",
    "# Cycling over params and computing the expecation value\n",
    "for i, param in enumerate(params):\n",
    "    \n",
    "    mu, sigma = param\n",
    "\n",
    "    # Compute the Expectation value for given mean and standard devation\n",
    "    expectation_value, _ = quad(gaussian_expectation_integrand, -np.inf, np.inf, args=(mu, sigma))\n",
    "\n",
    "    expectation_dict[i] = {\n",
    "        \"mu\": mu, \n",
    "        \"sigma\": sigma,\n",
    "        \"expectation\": round(expectation_value, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "731b1114-67bd-438c-97aa-daa6eff297a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'expectation': 0.0, 'mu': 0, 'sigma': 1},\n",
      " 1: {'expectation': 1.0, 'mu': 1, 'sigma': 1.5},\n",
      " 2: {'expectation': 1.5, 'mu': 1.5, 'sigma': 2},\n",
      " 3: {'expectation': 2.0, 'mu': 2, 'sigma': 2.5},\n",
      " 4: {'expectation': 2.5, 'mu': 2.5, 'sigma': 5},\n",
      " 5: {'expectation': 5.0, 'mu': 5, 'sigma': 10.5},\n",
      " 6: {'expectation': 10.5, 'mu': 10.5, 'sigma': 11}}\n"
     ]
    }
   ],
   "source": [
    "pprint(expectation_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc40f8e-72ad-40d9-8ee5-16b75517205f",
   "metadata": {},
   "source": [
    "We can see that the expectation values, i.e. the average values of $x$ under the given distribution, are always equal to the *mean* $\\mu$ parameter of the Gaussian distribution. That is why $\\mu$ is referred to as the *mean of the Gaussian distribution*. In probability theory, $\\mathbb{E}[x]$ is generally known as the *first order moment*. The *second-order moment* is defined as the expectation value of the square of $x$, i.e.:\n",
    "$$\n",
    "\\mathbb{E}[x^2] = \\int_{-\\infty}^{+\\infty} \\mathcal{N}(x | \\mu, \\sigma^2) x^2 dx\n",
    "$$\n",
    "Computing again the integral numerically for a set of possibile $\\mu$, $\\sigma$ parameters, we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "62bb7296-93ae-4ec9-8b54-441febf7a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_second_order_moment_integrand(x, mu, sigma):\n",
    "    return (x**2)*generate_gaussian(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "36cab97c-dcb1-43f2-a09d-203e9eda6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycling over params and computing the expecation value\n",
    "for i, param in enumerate(params):\n",
    "    \n",
    "    mu, sigma = param\n",
    "\n",
    "    # Compute the Expectation value for given mean and standard devation\n",
    "    second_order_moment, _ = quad(gaussian_second_order_moment_integrand, -np.inf, np.inf, args=(mu, sigma))\n",
    "\n",
    "    expectation_dict[i][\"second-order-moment\"] = round(second_order_moment, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7e7cf18c-711b-4012-8660-661def96935d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'mu': 0, 'sigma': 1, 'expectation': 0.0, 'second-order-moment': 1.0},\n",
       " 1: {'mu': 1, 'sigma': 1.5, 'expectation': 1.0, 'second-order-moment': 3.25},\n",
       " 2: {'mu': 1.5, 'sigma': 2, 'expectation': 1.5, 'second-order-moment': 6.25},\n",
       " 3: {'mu': 2, 'sigma': 2.5, 'expectation': 2.0, 'second-order-moment': 10.25},\n",
       " 4: {'mu': 2.5, 'sigma': 5, 'expectation': 2.5, 'second-order-moment': 31.25},\n",
       " 5: {'mu': 5,\n",
       "  'sigma': 10.5,\n",
       "  'expectation': 5.0,\n",
       "  'second-order-moment': 135.25},\n",
       " 6: {'mu': 10.5,\n",
       "  'sigma': 11,\n",
       "  'expectation': 10.5,\n",
       "  'second-order-moment': 231.25}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1e9b0-6e6e-41aa-bdce-d8c606127f6a",
   "metadata": {},
   "source": [
    "It may not be evident but one can actually verify that the second order moment is equal to $\\mu^2+\\sigma^2$ (the diligent reader can verify the result by computing the integration analytically. The integral can be solved in few steps applying the integration by part rule!). Therefore, we have:\n",
    "$$\\begin{gather}\n",
    "\\mathbb{E}[x] = \\int_{-\\infty}^{+\\infty} \\mathcal{N}(x | \\mu, \\sigma^2) x^2 dx = \\mu \\\\\n",
    "\\mathbb{E}[x^2] = \\int_{-\\infty}^{+\\infty} \\mathcal{N}(x | \\mu, \\sigma^2) x^2 dx = \\mu^2+\\sigma^2\n",
    "\\end{gather}\n",
    "$$\n",
    "It follows:\n",
    "$$\n",
    "\\text{var}[x] = \\mathbb{E}[x^2]-\\mathbb{E}[x]^2 = \\mu^2+\\sigma^2-\\mu^2 = \\sigma^2\n",
    "$$\n",
    "hence $\\sigma^2$ is called the *variance* of the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ce793c4f-0671-467f-a2e9-582a37e26ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_limit_theorem_demo(N):\n",
    "    sample_size = 10000\n",
    "    \n",
    "    sample_means = np.mean(np.random.rand(sample_size, N), axis=1)\n",
    "\n",
    "    # Plot histograms of sample means\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    fig.suptitle('Central Limit Theorem Demonstration')\n",
    "\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.hist(sample_means, bins=30, density=True, alpha=0.6, color='royalblue', edgecolor='black')\n",
    "    ax.set_title(f'Distribution of Sample Means (N = {N})')\n",
    "    ax.set_xlabel('Sample Mean')\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "06fa983e-aa01-42a4-af9d-3893a7b5126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8729c8cf624b490b99d253649ab72d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=49, description='N', min=1, step=2), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.central_limit_theorem_demo(N)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate Central Limit Theorem\n",
    "ipywidgets.interact(central_limit_theorem_demo, N=(1,100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec48c13-e1d2-4288-bcdf-aa69dac3a360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
